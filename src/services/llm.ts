import OpenAI from 'openai';
import fs from 'fs/promises';
import path from 'path';

/**
 * LLM ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ í˜ì´ë¡œë“œ ì¸í„°í˜ì´ìŠ¤
 */
export interface ReportPayload {
  lookback_days: number;
  portfolio: {
    cash_usd: number;
    holdings: Array<{
      symbol: string;
      shares: number;
      avg_cost: number;
    }>;
  };
  market: {
    date: string;
    sector_code: string;
    sector_title: string;
  };
  indicators: Record<string, {
    close: number;
    ema20: number;
    ema50: number;
    rsi14: number;
  }>;
  news: Array<{
    published_at: string;
    source: string;
    title: string;
    url: string;
    summary: string;
    sentiment: number;
    relevance: number;
  }>;
  scores: Record<string, number>;
}

/**
 * OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
 */
let openai: OpenAI | null = null;

function getOpenAIClient(): OpenAI {
  if (!openai) {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      throw new Error('OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
    }
    openai = new OpenAI({ apiKey });
  }
  return openai;
}

/**
 * OpenAI GPTë¥¼ ì‚¬ìš©í•œ ë³´ê³ ì„œ ìƒì„±
 */
export async function generateReportWithOpenAI(payload: ReportPayload): Promise<string> {
  try {
    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    const promptPath = path.join(process.cwd(), 'prompt.md');
    const systemPrompt = await fs.readFile(promptPath, 'utf8');

    // LLM ëª¨ë¸ ì„¤ì •
    const model = process.env.LLM_MODEL || 'gpt-4';

    console.log(`ğŸ¤– ${model}ì„ ì‚¬ìš©í•˜ì—¬ ë³´ê³ ì„œ ìƒì„± ì‹œì‘`);

    const messages = [
      {
        role: 'system' as const,
        content: systemPrompt
      },
      {
        role: 'user' as const,
        content: JSON.stringify(payload, null, 2)
      }
    ];

    const client = getOpenAIClient();
    const response = await client.chat.completions.create({
      model: model,
      messages: messages,
      temperature: 0.2,
      max_tokens: 4000,
    });

    const report = response.choices[0].message?.content;
    
    if (!report) {
      throw new Error('LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
    }

    console.log('âœ… LLM ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ');
    return report;

  } catch (error) {
    console.error('âŒ LLM ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨:', error);
    
    // ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë³´ê³ ì„œ ë°˜í™˜
    return generateFallbackReport(payload);
  }
}

/**
 * LLM ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ë³´ê³ ì„œ ìƒì„±
 */
function generateFallbackReport(payload: ReportPayload): string {
  const { market, portfolio, indicators, news } = payload;
  
  return `# ğŸ“Š ë°ì¼ë¦¬ ë¦¬í¬íŠ¸ â€“ ${market.date} (ì„¹í„°: ${market.sector_title})

## ìš”ì•½
- í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜: ê³„ì‚° ì¤‘...
- í˜„ê¸ˆ ë³´ìœ : $${portfolio.cash_usd.toFixed(2)}
- ë³´ìœ  ì¢…ëª© ìˆ˜: ${portfolio.holdings.length}ê°œ
- ì„¹í„° ëª¨ë©˜í…€: ë¶„ì„ ì¤‘...

## ì£¼ë¬¸ ì œì•ˆ
í˜„ì¬ LLM ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ì—†ì–´ ìë™ ì œì•ˆì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ìˆ˜ë™ìœ¼ë¡œ ì‹œì¥ ìƒí™©ì„ ê²€í† í•´ ì£¼ì„¸ìš”.

## ë³´ìœ  ì¢…ëª© ìƒíƒœ
${portfolio.holdings.map(holding => 
  `- ${holding.symbol}: ${holding.shares}ì£¼ (í‰ë‹¨ê°€: $${holding.avg_cost.toFixed(2)})`
).join('\n')}

## ì„¹í„° ë‰´ìŠ¤ Top ${Math.min(news.length, 5)}
${news.slice(0, 5).map(item => 
  `- ${item.title} (${item.source})`
).join('\n')}

## ë©”ì„œë“œ
- ì§€í‘œ: EMA(20/50), RSI(14)
- ê¸°ê°„: ìµœê·¼ ${payload.lookback_days}ì¼
- ìƒíƒœ: LLM ì„œë¹„ìŠ¤ ì¼ì‹œ ì¤‘ë‹¨

> *ë³¸ ë¦¬í¬íŠ¸ëŠ” íˆ¬ììë¬¸ì´ ì•„ë‹ˆë©°, ëª¨ë“  ê²°ì •ê³¼ ì±…ì„ì€ ì‚¬ìš©ìì—ê²Œ ìˆìŠµë‹ˆë‹¤.*`;
}

/**
 * ë‹¤ë¥¸ LLM ì œê³µì ì§€ì› (í–¥í›„ í™•ì¥ìš©)
 */
export async function generateReport(payload: ReportPayload): Promise<string> {
  const provider = process.env.LLM_PROVIDER || 'OPENAI';

  switch (provider.toUpperCase()) {
    case 'OPENAI':
      return await generateReportWithOpenAI(payload);
    
    // TODO: ë‹¤ë¥¸ LLM ì œê³µì ì¶”ê°€
    // case 'ANTHROPIC':
    //   return await generateReportWithAnthropic(payload);
    
    default:
      console.warn(`âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” LLM ì œê³µì: ${provider}, OpenAI ì‚¬ìš©`);
      return await generateReportWithOpenAI(payload);
  }
}